print("Add author name, company and license information")

import pandas as pd 
import numpy as np 
import GPyOpt
import GPy
import os
import glob
import pickle

# The logged parameters are writtent o .CSV so i can access these from the python pandas library easily. 
# .jsons are saved to the directory containing the information regarding initialization each agent.
# In the RL scheduler i can set max amount of steps to run, initially this will be set to allow for roughly 1 hour of training.
# The sum of the 'Total Reward' column is a measurement of total performance.
# BayesOpt can be implemented in a completely seperate python file than the AIs themselves, containing domain definitions for the hyperparameter search spaces.
# Use pandas to append the new parameter selection to xxx_parameters_opt.csv file, and create an argument/function that loads the last row from this file for use when running a new trial.

agent = 'ddpg'

#Append new agents to these dictionaries:
agent_preset = {'ddpg': 'ddpg_vrep_opt.py'}
agent_opt_dir = {'ddpg': 'ddpg_opt'}


#TODO: Modify the bounds define the bounding box for the hyperparameters
boundaries ={'example':
                [{'name': 'e_d',    'type': 'continuous', 'domain': (0.9,0.9999)},
                {'name': 'e_m',     'type': 'continuous', 'domain': (0.0,0.05)},
                {'name': 'gamma',   'type': 'continuous', 'domain': (0.8,1.0)},
                {'name': 'lr',      'type': 'continuous', 'domain': (0.0,0.05)},
                {'name': 'lr_d',    'type': 'continuous', 'domain': (0.0,0.05)},
                {'name': 'b_m',     'type': 'discrete',   'domain': (16, 32, 64, 128, 256)},
                {'name': 'layer1',  'type': 'discrete',   'domain': (20,24,28,32,36,40)},
                {'name': 'layer2',  'type': 'discrete',   'domain': (20,24,28,32,36,40)},
                {'name': 'layer1_a','type': 'categorical','domain': (0,1,2)}, #['tanh','relu','linear']
                {'name': 'layer2_a','type': 'categorical','domain': (0,1,2)}], 
            'ddpg':
                [{'name': 'actor_layer_1_nodes',    'type': 'discrete',   'domain': (32, 64, 128, 256)}, 
                {'name': 'actor_layer_2_nodes',     'type': 'discrete',   'domain': (16, 32, 64, 128, 256)}, 
                {'name': 'critic_layer_1_nodes',    'type': 'discrete',   'domain': (32, 64, 128, 256)}, 
                {'name': 'critic_layer_2_nodes',    'type': 'discrete',   'domain': (16, 32, 64, 128, 256)}, 
                {'name': 'discount_factor',         'type': 'continuous', 'domain': (0.8,1.0)}, 
                {'name': 'actor_learning_rate',     'type': 'continuous', 'domain': (0.0001, 0.1)}, 
                {'name': 'critic_learning_rate',    'type': 'continuous', 'domain': (0.0001, 0.1)}, 
                {'name': 'exploration_factor',      'type': 'continuous', 'domain': (0.5,10.0)}],
            }

#Retrieve the names of all the parameter variables being tuned:
param_names = []
for i in range(len(boundaries[agent])):
    param_names += [boundaries[agent][i]['name']]

def return_reward():
    ''' Loads the latest ~/expirements/*/worker_xxx.csv from the logged training data and returns the sum of all training rewards for that iteration.
    '''
    # Load the names of all *.csv files in directory
    
    # Filter list based on most recent edit
    
    # Load most recent edit

    # Sum and return all values in the 'Training Reward' column
    pass


def run_ai(param_list):
    ''' Runs the Ai created using the parameters defined by the parameter list generated by the bayesian optimizer
    '''
    # Load/create the .csv file as a dataframe
    # Append new parameters to dataframe

    try:
        parameters_dataframe = pd.read_csv('~/expirements/'+ agent_opt_dir[agent] +'optimization_parameters.csv')
        parameters_dataframe = parameters_dataframe.append( pd.DataFrame([param_list], columns=param_names), ignore_index=True)
    except Exception:
        parameters_dataframe = pd.DataFrame([param_list], columns=param_names)

    # Save the dataframe to .csv
    parameters_dataframe.to_csv('~/expirements/'+ agent_opt_dir[agent] +'optimization_parameters.csv')

    # Start the AI using os.system('python ' + agent_preset[agent]) This python script will wait for the agent to finish. 
    # The AI_opt script will load the parameters from the .csv and perform a training sequence.
    exit_flag = os.system('python ../agents/' + agent_preset[agent]) 

    # Provided the exit flag choose an appropriate action (was an error raised or was execution normal)
    if exit_flag == 0:
        # load the .csv file with the previous execution data and return the sum of training rewards
        return -return_reward()
    elif exit_flag != 0: 
        exit('An error occured while training the AI Agent')
    


def set_dtypes(X):
    ''' Changes the datatypes of the searchspace used by bayes-opt to fit that of tensorflow 
    '''
    [e_decay,e_min,gamma,lr,lr_d,BATCH_max,layer1,layer2,layer1_a,layer2_a] = X

    BATCH_max   =   int(BATCH_max)
    layer1      =   int(layer1)
    layer2      =   int(layer2)
    layer1_a    =   int(layer1_a)
    layer2_a    =   int(layer2_a)
    layer_activations = ['tanh', 'relu', 'linear']

    h_layers = {'layers':[layer1,layer2], 'activation':[layer_activations[layer1_a], layer_activations[layer2_a]], 'initializer':['he_normal', 'he_normal']}

    return [e_decay,e_min,gamma,lr,lr_d,BATCH_max,layer1,layer2,layer1_a,layer2_a], h_layers

################### Example function derived from my other repository
################### Is being altered to support the new AI Agents
if __name__=="__main__":
    ''' Main function instantiates a gaussian process optimizer from the GPyOpt package and performs Bayesian Optimization
    within the search domain defined in the boundaries dict.
    '''

    #Configure optimizer and set the number of optimization steps
    max_iter = 25
    ai_optimizer = GPyOpt.methods.BayesianOptimization(run_ai, domain=boundaries[agent],
                                                        initial_design_numdata = 8,   # Number of initial datapoints before optimizing
                                                        Initial_design_type = 'latin',
                                                        model_type= 'GP_MCMC',
                                                        acquisition_type='EI_MCMC',
                                                        normalize_Y = True) #http://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/devel/manual/GPyOpt_mixed_domain.ipynb
    
    
    
    #Run optimizer
    ai_optimizer.run_optimization(max_iter)

    # Evaluate using ai_optimizer.plot_convergence()
    ai_optimizer.plot_convergence()

    #Save the optimizer to pickle file, this is to backup the progress if optimization can continue
    print('TODO: Save optimizer class to pickle file')

    # All the hyperparameters come out of the optimization as float64 set_dtypes corrects the datatypes
    [x_optimum, h_layers] = set_dtypes(ai_optimizer.x_opt)

    #The estimated optimum is printed and saved to a file
    print("Best performance: ", x_optimum)

    #Save best performance to a file
    file_name = '~/expirements/'+ agent_opt_dir[agent] +'/Optimzed_performance_variables.csv'
    df = pd.DataFrame([x_optimum], columns=param_names)
    df.to_csv(file_name, index=False)