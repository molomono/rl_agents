import pandas as pd 
import sys
import numpy as np 

import os
import glob
import time

from constants_and_spaces import *


#Retrieve the names of all the parameter variables being tuned:
param_names = []
for i in range(len(boundaries[agent])):
    param_names += [boundaries[agent][i]['name']]

def return_reward(return_all_trials = False, normalize=False):
    ''' Loads the latest ~/experiments/agent_directory/worker_xxx.csv from the logged training data and returns the sum of all training rewards for that iteration.
    '''
    # Load the names of all *.csv files in directory
    file_list = os.listdir(home_path+'/experiments/'+agent_opt_dir[agent])
    # Filter list only log files remain
    file_list = [k for k in file_list if 'main_level' in k]
    # Append the directory location to the file_names
    for i in range(len(file_list)):
        file_list[i] = home_path+'/experiments/'+agent_opt_dir[agent]+'/'+file_list[i]
    #Sort the files based on the time of modification
    file_list.sort(key=os.path.getmtime)
    if return_all_trials:
        #TODO: TEST THIS BRANCH OF THE RETURN REWARD FUNCTION
        Y = []
        for file_location in file_list:				
            newest_training_data_dataframe = pd.read_csv(file_location)
            # Sum-up and return all values in the 'Training Reward' column
            total_reward = newest_training_data_dataframe['Training Reward'].sum()
            n_training_episodes = len(newest_training_data_dataframe['Training Reward'].notna())
            # Sum up and return all values in the 'Evluation Reward' column
            total_eval_reward = newest_training_data_dataframe['Evaluation Reward'].sum()
            n_evaluation_episodes = len(newest_training_data_dataframe['Evaluation Reward'].notna())
            
            # Normalize the Training reward by dividing it by the total number of training iterations
            if normalize:
                total_reward = total_reward/float(n_training_episodes)
                total_eval_reward = total_eval_reward/float(n_evaluation_episodes)
                
                # Add the normalized eval and training rewards together
                #total_reward = total_eval_reward
            Y += [[total_reward]]
        return np.asarray(Y)
    else:
        # Load most recent edit
        newest_training_data_dataframe = pd.read_csv(file_list[-1])
        # Sum-up and return all values in the 'Training Reward' column
        total_reward = newest_training_data_dataframe['Training Reward'].sum()
        n_training_episodes = len(newest_training_data_dataframe['Training Reward'].notna())
        # Sum up and return all values in the 'Evluation Reward' column
        total_eval_reward = newest_training_data_dataframe['Evaluation Reward'].sum()
        n_evaluation_episodes = len(newest_training_data_dataframe['Evaluation Reward'].notna())
        
        # Normalize the Training reward by dividing it by the total number of training iterations
        if normalize:
            total_reward = total_reward/float(n_training_episodes)
            total_eval_reward = total_eval_reward/float(n_evaluation_episodes)
            # Add the normalized eval and training rewards together
            #total_reward = total_eval_reward
        return total_reward


def run_ai(param_list):
    ''' Runs the Ai created using the parameters defined by the parameter list generated by the bayesian optimizer
    '''
    # Load/create the .csv file as a dataframe
    # Append new parameters to dataframe
    print(param_names)
    print(param_list)
    
    if glob.glob(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv'):
        parameters_dataframe = pd.read_csv(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv')
        parameters_dataframe = parameters_dataframe.append( pd.DataFrame(param_list, columns=param_names), ignore_index=True)
    else:
        if not os.path.exists(home_path + '/experiments/'+ agent_opt_dir[agent]):
            os.mkdir(home_path + '/experiments/'+ agent_opt_dir[agent])
        parameters_dataframe = pd.DataFrame(param_list, columns=param_names)
        
    # Save the dataframe to .csv
    parameters_dataframe.to_csv(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv', index=False)

    # Start the AI using os.system('python ' + agent_preset[agent]) This python script will wait for the agent to finish. 
    # The AI_opt script will load the parameters from the .csv and perform a training sequence.
    exit_flag = os.system('python ../agents/' + agent_preset[agent]) 

    # Provided the exit flag choose an appropriate action (was an error raised or was execution normal)
    if exit_flag == 0:
       # load the .csv file with the previous execution data and return the sum of training rewards
       return -return_reward(normalize = True)
    elif exit_flag != 0: 
        print('An error occured while training the AI Agent')
        remove_failed_optimization_iteration()
        quit()
	
def load_params_of_all_trials(return_dataframe = False):
	''' Load all the hyperparameters from the params.csv file and return them as a numpy array
	'''
	parameters_dataframe = pd.read_csv(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv')
	if return_dataframe:
		return parameters_dataframe
	else:
		return parameters_dataframe.values

def remove_failed_optimization_iteration(remove_param = True, remove_log_arg = False):
    ''' When an iteration fails it leaves behind a log file that isn't complete, it can still be used to draw the sum of total rewards but 
    doing this will skew the hyperparameter predictions in a bad way.
	
    This function is used to delete the incomplete .csv file and alter the parameters.csv file to remove the last row.
    '''
    num_iterations = 0
    if remove_param:
        #Load parameters.csv 
        parameters_dataframe = pd.read_csv(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv')
        pd.DataFrame(parameters_dataframe.values[:-1,:], columns=param_names).to_csv(home_path + '/experiments/'+ agent_opt_dir[agent] +'/optimization_parameters.csv', index=False)
        #Number of iterations remaining after deleting the previous entry
        num_iterations = len(parameters_dataframe)-1
  
    # Load the names of all *.csv files in directory
    file_list = os.listdir(home_path+'/experiments/'+agent_opt_dir[agent])
    # Filter list only log files remain
    file_list = [k for k in file_list if 'main_level' in k]
    num_log_files = len(file_list)
    
    # If the number of log files is more than the parameter entries remove the newest log file
    remove_log = num_log_files > num_iterations
    if remove_log or remove_log_arg:     
        # Append the directory location to the file_names
        for i in range(len(file_list)):
            file_list[i] = home_path+'/experiments/'+agent_opt_dir[agent]+'/'+file_list[i]
        #Sort the files based on the time of modification
        file_list.sort(key=os.path.getmtime)
        #Remove the last log file
        os.remove(file_list[-1])
